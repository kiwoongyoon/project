{"cells":[{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-04-03T11:25:30.236409Z","iopub.status.busy":"2024-04-03T11:25:30.235974Z","iopub.status.idle":"2024-04-03T11:25:30.246304Z","shell.execute_reply":"2024-04-03T11:25:30.245370Z","shell.execute_reply.started":"2024-04-03T11:25:30.236377Z"},"trusted":true},"outputs":[{"data":{"text/plain":["device(type='cuda', index=0)"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["import torch\n","import torchvision\n","import torchvision.transforms as transforms\n","from torchvision.models import resnet18\n","from torch.utils.data import Dataset, DataLoader, random_split\n","import torch.nn as nn\n","import torch.optim as optim\n","\n","import numpy as np\n","import pandas as pd \n","import random \n","import os\n","\n","# MNIST 데이터셋을 위한 변환 정의\n","transform = transforms.Compose([\n","    transforms.Resize((224, 224)), # 이미지 크기 조정\n","    transforms.Grayscale(num_output_channels=3), # 그레이스케일 이미지를 3채널로 변환\n","    transforms.ToTensor(),\n","])\n","# MNIST 데이터셋 로드\n","train = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n","# trainloader = torch.utils.data.DataLoader(train, batch_size=64, shuffle=True)\n","test = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n","# testloader = torch.utils.data.DataLoader(test, batch_size=64, shuffle=False)\n","\n","\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","device"]},{"cell_type":"markdown","metadata":{},"source":["# Seed 고정하기"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["def seed_everything(seed):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = True\n","\n","seed_everything(42) # Seed 고정"]},{"cell_type":"markdown","metadata":{},"source":["# 하이퍼 파라미터 정의하기 "]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["learning_rate = 0.001\n","training_epochs = 10\n","BATCHSIZE = 64\n","\n","train_dataset_size = int(len(train) * 0.9)\n","validation_dataset_size = int(len(train) * 0.1)\n","train_dataset, validation_dataset = random_split(train, [train_dataset_size, validation_dataset_size])\n","train_dataset_loader = DataLoader(dataset=train_dataset, batch_size=BATCHSIZE, shuffle=True)\n","validation_dataset_loader = DataLoader(dataset=validation_dataset, batch_size=BATCHSIZE, shuffle=True)\n","test_dataset_loader = DataLoader(dataset=test, batch_size=BATCHSIZE, shuffle=True)"]},{"cell_type":"markdown","metadata":{},"source":["# ResNet 모델 정의 , 손실함수 정의하기 "]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-04-03T11:25:36.653678Z","iopub.status.busy":"2024-04-03T11:25:36.653374Z","iopub.status.idle":"2024-04-03T11:25:37.039743Z","shell.execute_reply":"2024-04-03T11:25:37.038666Z","shell.execute_reply.started":"2024-04-03T11:25:36.653652Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/kiwoongyoon/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/home/kiwoongyoon/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n"]}],"source":["# 사전 학습된 ResNet 모델 로드 및 수정\n","model = resnet18(pretrained=True) \n","model.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False) \n","model.fc = nn.Linear(model.fc.in_features, 10) \n","model.to(device)\n","\n","loss = nn.CrossEntropyLoss()\n","optim = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","def model_train(dataloader, model, loss_function, optimizer):\n","\n","    model.train()\n","\n","    train_loss_sum = train_correct = train_total = 0\n","\n","    total_train_batch = len(dataloader)\n","\n","    for images, labels in dataloader:\n","\n","        x_train = images.to(device)\n","        y_train = labels.to(device)\n","\n","        outputs = model(x_train)\n","        loss = loss_function(outputs, y_train)\n","\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        train_loss_sum += loss.item()\n","\n","        train_total += y_train.size(0)\n","        train_correct += ((torch.argmax(outputs, 1)==y_train)).sum().item()\n","\n","    train_avg_loss = train_loss_sum / total_train_batch\n","    train_avg_accuracy = 100*train_correct / train_total\n","\n","    return (train_avg_loss, train_avg_accuracy)\n","\n","def model_evaluate(dataloader, model, loss_function, optimizer):\n","\n","    model.eval()\n","\n","    with torch.no_grad():\n","\n","        val_loss_sum = val_correct = val_total = 0\n","\n","        total_val_batch = len(dataloader)\n","\n","        for images, labels in dataloader:\n","\n","            x_val = images.to(device)\n","            y_val = labels.to(device)\n","\n","            outputs = model(x_val)\n","            loss = loss_function(outputs, y_val)\n","\n","            val_loss_sum += loss.item()\n","\n","            val_total += y_val.size(0)\n","            val_correct += ((torch.argmax(outputs, 1)==y_val)).sum().item()\n","\n","        val_avg_loss = val_loss_sum / total_val_batch\n","        val_avg_accuracy = 100*val_correct / val_total\n","\n","    return (val_avg_loss, val_avg_accuracy)\n","\n","def model_test(dataloader,loss_func, model):\n","\n","    model.eval()\n","\n","    with torch.no_grad():\n","\n","        test_loss_sum = test_correct = test_total = 0\n","\n","        total_test_batch = len(dataloader)\n","\n","        for images, labels in dataloader:\n","\n","            x_test = images.to(device)\n","            y_test = labels.to(device)\n","\n","            outputs = model(x_test)\n","            loss = loss_func(outputs, y_test)\n","\n","            test_loss_sum += loss.item()\n","\n","            test_total += y_test.size(0)\n","            test_correct += ((torch.argmax(outputs, 1)==y_test)).sum().item()\n","\n","        test_avg_loss = test_loss_sum / total_test_batch\n","        test_avg_accuracy = 100*test_correct / test_total\n","\n","        print('accuracy:', test_avg_accuracy)\n","        print('loss:', test_avg_loss)"]},{"cell_type":"markdown","metadata":{},"source":["# 모델 학습 및 추론"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["accuracy: 98.97\n","loss: 0.03476915317683949\n","epoch: 01 train acc = 97.765 val acc = 98.817\n","accuracy: 98.62\n","loss: 0.043150850962832644\n","epoch: 02 train acc = 98.894 val acc = 98.350\n","accuracy: 99.39\n","loss: 0.020310871276248522\n","epoch: 03 train acc = 99.161 val acc = 99.250\n","accuracy: 99.29\n","loss: 0.02381780717739165\n","epoch: 04 train acc = 99.222 val acc = 99.067\n","accuracy: 99.29\n","loss: 0.021216130101000635\n","epoch: 05 train acc = 99.404 val acc = 99.233\n","accuracy: 99.3\n","loss: 0.02430996358573324\n","epoch: 06 train acc = 99.444 val acc = 98.983\n","accuracy: 99.18\n","loss: 0.02489619329250794\n","epoch: 07 train acc = 99.431 val acc = 99.200\n","accuracy: 99.39\n","loss: 0.019817810152536097\n","epoch: 08 train acc = 99.670 val acc = 99.583\n","accuracy: 99.31\n","loss: 0.024669068379715182\n","epoch: 09 train acc = 99.604 val acc = 99.200\n","accuracy: 99.3\n","loss: 0.02303751501787968\n","epoch: 10 train acc = 99.572 val acc = 99.167\n"]}],"source":["\n","train_accuracy_list = []\n","val_accuracy_list = []\n","for epoch in range(training_epochs):\n","\n","    train_avg_loss, train_avg_accuracy = model_train(train_dataset_loader, model, loss, optim)\n","    train_accuracy_list.append(train_avg_accuracy)\n","    val_avg_loss, val_avg_accuracy = model_evaluate(validation_dataset_loader, model, loss, optim)\n","    val_accuracy_list.append(val_avg_accuracy)\n","\n","    model_test(test_dataset_loader,loss, model)\n","    print('epoch:', '%02d' % (epoch + 1),  'train acc =', '{:.3f}'.format(train_avg_accuracy),    'val acc =', '{:.3f}'.format(val_avg_accuracy))\n"]},{"cell_type":"markdown","metadata":{},"source":["# ResNet 모델을 활용한 MNIST 데이터 분류\n","\n","   ## * 개요\n"," 사전 학습된 ResNet18 모델을 사용하여 MNIST 데이터셋을 분류하는 실험을 진행하였습니다. 일반적인 CNN 모델과 비교했을 때, ResNet 모델이 더 우수한 성능을 보여주었습니다. 그러나, 매 epoch마다 테스트 데이터에 대한 정확도를 측정한 결과, 예측 결과가 지속적으로 상승하지는 않음을 확인하였습니다. 적절한 epoch을 선택해야 할 거 같습니다. \n","\n","## * 모델 수정 및 학습 과정\n","\n","사전 학습된 ResNet18 모델을 로드하고, MNIST 데이터셋에 적합하도록 다음과 같이 모델의 일부를 수정하였습니다.\n","\n","- Conv(`conv1`)를 MNIST 데이터셋에 맞게 조정하였습니다.\n","- Fully connected (`fc`)를 수정했습니다. \n","\n","이후, 수정된 모델을 이용하여 각 epoch마다 학습 데이터셋과 검증 데이터셋에 대한 정확도를 구했습니다.\n","\n","\n","## * 결론\n","\n","   사전 학습된 ResNet 모델이 MNIST 데이터 분류 작업에서 일반 CNN 모델보다 더 우수한 성능을 보여주었음을 확인하였습니다. 그러나, 모델 학습 과정에서 적절한 epoch 수의 선택이 중요함을 확인했습니다. \n"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30674,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
